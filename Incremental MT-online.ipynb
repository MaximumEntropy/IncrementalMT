{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "import codecs\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('/usr1/home/ssandeep/UltraDeep/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from network import LSTM\n",
    "from layer import HiddenLayer, EmbeddingLayer\n",
    "from learning_method import LearningMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_oracle = '/usr1/home/ssandeep/IncrementalMT/oracle.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = [line.strip().split(' ||| ') for line in codecs.open(path_to_oracle, 'r', encoding='utf8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "curr_sentence_pointer = 0\n",
    "for ind, line in enumerate(lines):\n",
    "    if len(line) == 1 and line[0] == '':\n",
    "        sentences.append(lines[curr_sentence_pointer:ind])\n",
    "        curr_sentence_pointer = ind + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soure_words = set()\n",
    "for sentence in sentences:\n",
    "    source_sentence = sentence[0][0]\n",
    "    for word in source_sentence.split():\n",
    "        soure_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_words = set()\n",
    "for sentence in sentences:\n",
    "    target_sentence = sentence[1][0]\n",
    "    for word in target_sentence.split():\n",
    "        target_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    for state in sentence[2:]:\n",
    "        assert len(state) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_word2ind = {word:ind for ind, word in enumerate(soure_words)}\n",
    "source_ind2word = {ind:word for ind, word in enumerate(soure_words)}\n",
    "target_word2ind = {word:ind for ind, word in enumerate(target_words)}\n",
    "target_ind2word = {ind:word for ind, word in enumerate(target_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_word2ind['<s>'] = len(source_word2ind)\n",
    "source_word2ind['</s>'] = len(source_word2ind) + 1\n",
    "source_word2ind['$NONE$'] = len(source_word2ind) + 2\n",
    "target_word2ind['<s>'] = len(target_word2ind)\n",
    "target_word2ind['</s>'] = len(target_word2ind) + 1\n",
    "target_word2ind['$NONE$'] = len(target_word2ind) + 2\n",
    "source_ind2word[len(source_word2ind)] = '<s>'\n",
    "source_ind2word[len(source_word2ind) + 1] = '</s>'\n",
    "source_ind2word[len(source_word2ind) + 2] = '$NONE$'\n",
    "source_ind2word[len(source_word2ind) + 3] = '<ss>'\n",
    "source_ind2word[len(source_word2ind) + 4] = '</se>'\n",
    "source_ind2word[len(source_word2ind) + 5] = '<fcs>'\n",
    "source_ind2word[len(source_word2ind) + 6] = '</fce>'\n",
    "target_ind2word[len(target_word2ind)] = '<s>' \n",
    "target_ind2word[len(target_word2ind) + 1] = '</s>' \n",
    "target_ind2word[len(target_word2ind) + 2] = '$NONE$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71180"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_input = T.ivector()\n",
    "forward_context_input = T.ivector()\n",
    "target_input = T.ivector()\n",
    "action_prediction = T.scalar()\n",
    "target_output = T.ivector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate synthetic data to test dimensions\n",
    "syn_stack_input = np.random.randint(low=0, high=len(source_word2ind), size=(5,)).astype(np.int32)\n",
    "syn_forward_context_input = np.random.randint(low=0, high=len(source_word2ind), size=(6,)).astype(np.int32)\n",
    "syn_action_prediction = np.random.randint(low=0, high=2, size=(1,)).astype(np.float32)[0]\n",
    "syn_target_input = np.random.randint(low=0, high=len(target_word2ind), size=(7,)).astype(np.int32)\n",
    "syn_target_output = np.random.randint(low=0, high=len(target_word2ind), size=(7,)).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "('Error allocating 583106560 bytes of device memory (out of memory).', \"you might consider using 'theano.shared(..., borrow=True)'\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-cffb73ebc1ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mtarget_lstm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtgt_emb_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtgt_lstm_hid_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'target_lstm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0maction_prediction_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHiddenLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstack_source_lstm_forward\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_dim\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mforward_context_lstm_forward\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtarget_word_decoding_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHiddenLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtgt_lstm_hid_dim\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msrc_lstm_hid_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_word2ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mprojection_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHiddenLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msrc_lstm_hid_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtgt_emb_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tanh'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr1/home/ssandeep/UltraDeep/layer.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dim, output_dim, bias, activation, name)\u001b[0m\n\u001b[0;32m     35\u001b[0m         self.weights = create_shared(\n\u001b[0;32m     36\u001b[0m             \u001b[0mrandom_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'__weights'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         )\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr1/home/ssandeep/UltraDeep/utils.pyc\u001b[0m in \u001b[0;36mcreate_shared\u001b[1;34m(value, name)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[0mCreate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mshared\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \"\"\"\n\u001b[1;32m--> 105\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr1/home/ssandeep/anaconda2/lib/python2.7/site-packages/theano/compile/sharedvalue.pyc\u001b[0m in \u001b[0;36mshared\u001b[1;34m(value, name, strict, allow_downcast, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m                 var = ctor(value, name=name, strict=strict,\n\u001b[1;32m--> 247\u001b[1;33m                            allow_downcast=allow_downcast, **kwargs)\n\u001b[0m\u001b[0;32m    248\u001b[0m                 \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_tag_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr1/home/ssandeep/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/var.pyc\u001b[0m in \u001b[0;36mfloat32_shared_constructor\u001b[1;34m(value, name, strict, allow_downcast, borrow, broadcastable, target)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;31m# type.broadcastable is guaranteed to be a tuple, which this next\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;31m# function requires\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0mdeviceval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_support_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcastable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: ('Error allocating 583106560 bytes of device memory (out of memory).', \"you might consider using 'theano.shared(..., borrow=True)'\")"
     ]
    }
   ],
   "source": [
    "# Neural Inventory\n",
    "\n",
    "src_emb_dim      = 256  # source word embedding dimension\n",
    "tgt_emb_dim      = 256  # target word embedding dimension\n",
    "src_lstm_hid_dim = 512  # source LSTMs hidden dimension\n",
    "tgt_lstm_hid_dim = 2 * src_lstm_hid_dim  # target LSTM hidden dimension\n",
    "\n",
    "\n",
    "source_embedding = EmbeddingLayer(input_dim=len(source_word2ind) + 1, output_dim=src_emb_dim)\n",
    "target_embedding = EmbeddingLayer(input_dim=len(target_word2ind) + 1, output_dim=tgt_emb_dim)\n",
    "\n",
    "stack_source_lstm_forward = LSTM(input_dim=src_emb_dim, hidden_dim=src_lstm_hid_dim, name='source_stack_lstm', with_batch=False)\n",
    "stack_source_lstm_backward = LSTM(input_dim=src_emb_dim, hidden_dim=src_lstm_hid_dim, name='source_stack_lstm', with_batch=False)\n",
    "\n",
    "forward_context_lstm_forward = LSTM(input_dim=src_emb_dim, hidden_dim=src_lstm_hid_dim, name='source_forward_context_lstm', with_batch=False)\n",
    "forward_context_lstm_backward = LSTM(input_dim=src_emb_dim, hidden_dim=src_lstm_hid_dim, name='source_forward_context_lstm', with_batch=False)\n",
    "\n",
    "target_lstm = LSTM(input_dim = 2 * tgt_emb_dim, hidden_dim=tgt_lstm_hid_dim, name='target_lstm', with_batch=False)\n",
    "action_prediction_weights = HiddenLayer(input_dim=2 * stack_source_lstm_forward.hidden_dim + 2 * forward_context_lstm_forward.hidden_dim, output_dim=1)\n",
    "target_word_decoding_weights = HiddenLayer(input_dim=tgt_lstm_hid_dim + 2 * src_lstm_hid_dim, output_dim=len(target_word2ind), activation='softmax')\n",
    "projection_weights = HiddenLayer(input_dim = 2 * src_lstm_hid_dim, output_dim = tgt_emb_dim, activation='tanh')\n",
    "\n",
    "action_params = source_embedding.params + stack_source_lstm_forward.params + stack_source_lstm_backward.params + forward_context_lstm_forward.params + forward_context_lstm_backward.params + action_prediction_weights.params\n",
    "seq_seq_params = source_embedding.params + stack_source_lstm_forward.params + stack_source_lstm_backward.params + target_embedding.params + target_lstm.params[:-1] + projection_weights.params + target_word_decoding_weights.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# The computational graph for this method\n",
    "# =====================================================\n",
    "\n",
    "# Get the embedding matrices seq_len x embdding_dim\n",
    "stack_embedding_matrix = source_embedding.link(stack_input)\n",
    "forward_context_embedding_matrix = source_embedding.link(forward_context_input)\n",
    "\n",
    "# ===========================================================\n",
    "# Get LSTM representations of the stack, forward context\n",
    "# ===========================================================\n",
    "\n",
    "# Stack Representation\n",
    "stack_source_lstm_forward.link(stack_embedding_matrix)\n",
    "stack_source_lstm_backward.link(stack_embedding_matrix[::-1, :])\n",
    "stack_lstm_representation = T.concatenate((stack_source_lstm_forward.h, stack_source_lstm_backward.h[::-1,:]), axis=1)\n",
    "print 'stack_lstm_representation', stack_lstm_representation.eval({stack_input:syn_stack_input}).shape\n",
    "\n",
    "# Forward Context Representation\n",
    "forward_context_lstm_forward.link(forward_context_embedding_matrix)\n",
    "forward_context_lstm_backward.link(forward_context_embedding_matrix[::-1, :])\n",
    "forward_context_representation = T.concatenate((forward_context_lstm_forward.h, forward_context_lstm_backward.h[::-1,:]), axis=1)\n",
    "print 'forward_context_lstm_representation', forward_context_representation.eval({forward_context_input:syn_forward_context_input}).shape\n",
    "\n",
    "# Concatenate representations and make a prediction about what action to take\n",
    "concatenated_representation = T.concatenate((stack_lstm_representation[-1], forward_context_representation[-1]))\n",
    "print 'concatenated_representation', concatenated_representation.eval({stack_input:syn_stack_input, forward_context_input:syn_forward_context_input}).shape\n",
    "prediction = action_prediction_weights.link(concatenated_representation).mean() # .mean() is a hack to make it a scalar (since its only a single value, it shouldn't matter)\n",
    "print 'predicton', prediction.eval({stack_input:syn_stack_input, forward_context_input:syn_forward_context_input})\n",
    "\n",
    "# Compute squared-error loss between predicted action and gold action\n",
    "action_prediction_loss = ((action_prediction - prediction) ** 2).mean()\n",
    "print 'action_prediction_loss', action_prediction_loss.eval({stack_input:syn_stack_input, forward_context_input:syn_forward_context_input, action_prediction:syn_action_prediction})\n",
    "\n",
    "# Get target input embeddings\n",
    "target_embeddings = target_embedding.link(target_input)\n",
    "print 'target_embeddings', target_embeddings.eval({target_input:syn_target_input}).shape\n",
    "\n",
    "target_lstm.h_0 = stack_lstm_representation[-1]\n",
    "print 'target_lstm_h0', target_lstm.h_0.eval({stack_input:syn_stack_input}).shape\n",
    "repeated_src_context = T.repeat(stack_lstm_representation[-1].dimshuffle('x', 0), target_embeddings.shape[0], axis=0)\n",
    "print 'repeated_src_context', repeated_src_context.eval({stack_input:syn_stack_input, target_input:syn_target_input}).shape\n",
    "repeated_src_context = projection_weights.link(repeated_src_context)\n",
    "print 'repeated_src_context', repeated_src_context.eval({stack_input:syn_stack_input, target_input:syn_target_input}).shape\n",
    "target_embeddings = T.concatenate((target_embeddings, repeated_src_context), axis=1)\n",
    "print 'target_embeddings', target_embeddings.eval({stack_input:syn_stack_input, target_input:syn_target_input}).shape\n",
    "target_lstm.link(target_embeddings)\n",
    "print 'target_lstm', target_lstm.h.eval({stack_input:syn_stack_input, target_input:syn_target_input}).shape\n",
    "\n",
    "transition = target_lstm.h.dot(stack_lstm_representation.transpose())\n",
    "transition = transition.dot(stack_lstm_representation)\n",
    "print 'transition', transition.eval({stack_input:syn_stack_input, target_input:syn_target_input}).shape\n",
    "\n",
    "transition_last = T.concatenate([transition, target_lstm.h], axis=1)\n",
    "decoded_words = target_word_decoding_weights.link(transition_last)\n",
    "print 'decoded_words', decoded_words.eval({stack_input:syn_stack_input, target_input:syn_target_input}).shape\n",
    "decoding_loss = T.nnet.categorical_crossentropy(decoded_words, target_output).mean()\n",
    "print 'decoding_loss', decoding_loss.eval({stack_input:syn_stack_input, target_input:syn_target_input, target_output:syn_target_output})\n",
    "\n",
    "'''\n",
    "# Appened source representation to input at every step\n",
    "repeated_src_context = T.repeat(stack_lstm_representation[-1].dimshuffle('x', 0), target_embeddings.shape[0], axis=0)\n",
    "#repeated_src_context = proj_layer2.link(repeated_src_context)\n",
    "target_embeddings = T.concatenate((target_embeddings, repeated_src_context), axis=1)\n",
    "\n",
    "# Get the decoded sentence by connecting Encoder & Decoder\n",
    "connection = projection_weights.link(stack_lstm_representation[-1])\n",
    "print 'connection', connection.eval({stack_input:syn_stack_input}).shape\n",
    "target_lstm.h_0 = connection\n",
    "target_lstm.link(target_embeddings)\n",
    "print 'target_lstm', target_lstm.h.eval({stack_input:syn_stack_input, target_input:syn_target_input}).shape\n",
    "\n",
    "transition = target_lstm.h.dot(stack_lstm_representation.transpose())\n",
    "transition = transition.dot(stack_lstm_representation)\n",
    "print 'transition', transition.eval({stack_input:syn_stack_input, target_input:syn_target_input}).shape\n",
    "\n",
    "# Decode words\n",
    "decoded_words = target_word_decoding_weights.link(target_lstm.h)\n",
    "print 'decoded_words', decoded_words.eval({stack_input:syn_stack_input, target_input:syn_target_input}).shape\n",
    "\n",
    "# Compute seq-seq loss\n",
    "decoding_loss = T.nnet.categorical_crossentropy(decoded_words, target_output).mean()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Update parameters using ADAM\n",
    "'''\n",
    "updates_action=LearningMethod(clip=5.0).get_updates('adam', action_prediction_loss, action_params)\n",
    "\n",
    "#updates_action = Optimizer().adam(\n",
    "#                action_prediction_loss,\n",
    "#                action_params,\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Update parameters using ADAM\n",
    "'''\n",
    "updates_seq_seq = LearningMethod(clip=5.0).get_updates('adam', decoding_loss, seq_seq_params)\n",
    "#updates_seq_eq = Optimizer().adam(\n",
    "#                decoding_loss,\n",
    "#                seq_seq_params,\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_train_action = theano.function(\n",
    "    inputs=[stack_input, forward_context_input, action_prediction],\n",
    "    outputs=action_prediction_loss,\n",
    "    updates=updates_action\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_train_seq_seq = theano.function(\n",
    "    inputs=[stack_input, target_input, target_output],\n",
    "    outputs=decoding_loss,\n",
    "    updates=updates_seq_seq\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_get_action = theano.function(\n",
    "    inputs=[stack_input, forward_context_input],\n",
    "    outputs=prediction,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ind, sentence in enumerate(sentences):\n",
    "    action_losses = []\n",
    "    seq_seq_losses = []\n",
    "    for state in sentence[2:]:\n",
    "        word = state[0]\n",
    "        action = state[1]\n",
    "        stack_state = state[2].strip().split()\n",
    "        forward_context = state[3].strip().split()\n",
    "        translation = state[4].strip().split()\n",
    "        stack_words = [source_word2ind[word] for word in stack_state]\n",
    "        forward_context_words = [source_word2ind[word] for word in forward_context][::-1]\n",
    "        action = 1.0 if action == 'T' else 0.0\n",
    "        translation_words = [target_word2ind['<s>']] + [target_word2ind[word] for word in translation] + [target_word2ind['</s>']]\n",
    "        action_loss = f_train_action(stack_words, forward_context_words, action)\n",
    "        #seq_seq_loss = f_train_seq_seq(stack_words, translation_words[:-1], translation_words[1:])\n",
    "        action_losses.append(action_loss)\n",
    "        #seq_seq_losses.append(seq_seq_loss)\n",
    "    print 'Sentence %d out of %d action loss %f ' % (ind, len(sentences), np.mean(action_losses))\n",
    "    #print 'Sentence %d out of %d seq-seq loss %f ' % (ind, len(sentences), np.mean(seq_seq_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-103c9e3bffae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "print translation.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[71181, 71179]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_words[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
