{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 4,
=======
   "execution_count": 21,
>>>>>>> Stashed changes
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_alignments = '/usr0/home/glample/Research/IncrementalMT/en-zh.tok.sym.grow-diag'\n",
<<<<<<< Updated upstream
=======
    "path_to_en = '/usr0/home/glample/Research/IncrementalMT/english_data.tok'\n",
    "path_to_fr = '/usr0/home/glample/Research/IncrementalMT/chinese_data.tok'\n",
>>>>>>> Stashed changes
    "path_to_bitext = '/usr0/home/glample/Research/IncrementalMT/en-zh.tok'"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 13,
=======
   "execution_count": 22,
>>>>>>> Stashed changes
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alignments = [line.strip().split() for line in open(path_to_alignments, 'r')][900003:]\n",
<<<<<<< Updated upstream
    "bitext = [line.strip().split(' ||| ') for line in codecs.open(path_to_bitext, 'r', encoding='utf8')][900003:]"
=======
    "#english_sents = [line.strip().split() for line in codecs.open(path_to_en, 'r', encoding='utf8')][900003:]\n",
    "#french_sents = [line.strip().split() for line in codecs.open(path_to_fr, 'r', encoding='utf8')][900003:]\n",
    "bitext = [line.strip().split(' ||| ') for line in open(path_to_bitext, 'r')][900003:]"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 14,
=======
   "execution_count": 33,
>>>>>>> Stashed changes
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "assert len(alignments) == len(bitext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_sents = [x[0].split() for x in bitext]\n",
    "french_sents = [x[1].split() for x in bitext]"
=======
    "english_sents = [x[1].split() for x in bitext]\n",
    "french_sents = [x[0].split() for x in bitext]"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 22,
=======
   "execution_count": 34,
>>>>>>> Stashed changes
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_alignment(alignment):\n",
    "    forward_alignment = {}\n",
    "    backward_alignment = {}\n",
    "    for alignment_pair in alignment:\n",
    "        alignment_pair = [int(x) for x in alignment_pair.split('-')]\n",
    "        if alignment_pair[0] not in forward_alignment:\n",
    "            forward_alignment[alignment_pair[0]] = [alignment_pair[1]]\n",
    "        else:\n",
    "            forward_alignment[alignment_pair[0]].append(alignment_pair[1])\n",
    "        if alignment_pair[1] not in backward_alignment:\n",
    "            backward_alignment[alignment_pair[1]] = [alignment_pair[0]]\n",
    "        else:\n",
    "            backward_alignment[alignment_pair[1]].append(alignment_pair[0])\n",
    "    return forward_alignment, backward_alignment"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 23,
=======
   "execution_count": 35,
>>>>>>> Stashed changes
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_not_in_target(alignment):\n",
    "    targets = [int(x.split('-')[0]) for x in alignment]\n",
    "    return set(range(max(targets))) - set(targets)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 24,
=======
   "execution_count": 40,
>>>>>>> Stashed changes
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Finished 0 out of 45020 \n",
      "Finished 1000 out of 45020 \n",
      "Finished 2000 out of 45020 \n",
      "Finished 3000 out of 45020 \n",
      "Finished 4000 out of 45020 \n",
      "Finished 5000 out of 45020 \n",
      "Finished 6000 out of 45020 \n",
      "Finished 7000 out of 45020 \n",
      "Finished 8000 out of 45020 \n",
      "Finished 9000 out of 45020 \n",
      "Finished 10000 out of 45020 \n",
      "Finished 11000 out of 45020 \n",
      "Finished 12000 out of 45020 \n",
      "Finished 13000 out of 45020 \n",
      "Finished 14000 out of 45020 \n",
      "Finished 15000 out of 45020 \n",
      "Finished 16000 out of 45020 \n",
      "Finished 17000 out of 45020 \n",
      "Finished 18000 out of 45020 \n",
      "Finished 19000 out of 45020 \n",
      "Finished 20000 out of 45020 \n",
      "Finished 21000 out of 45020 \n",
      "Finished 22000 out of 45020 \n",
      "Finished 23000 out of 45020 \n",
      "Finished 24000 out of 45020 \n",
      "Finished 25000 out of 45020 \n",
      "Finished 26000 out of 45020 \n",
      "Finished 27000 out of 45020 \n",
      "Finished 28000 out of 45020 \n",
      "Finished 29000 out of 45020 \n",
      "Finished 30000 out of 45020 \n",
      "Finished 31000 out of 45020 \n",
      "Finished 32000 out of 45020 \n",
      "Finished 33000 out of 45020 \n",
      "Finished 34000 out of 45020 \n",
      "Finished 35000 out of 45020 \n",
      "Finished 36000 out of 45020 \n",
      "Finished 37000 out of 45020 \n",
      "Finished 38000 out of 45020 \n",
      "Finished 39000 out of 45020 \n",
      "Finished 40000 out of 45020 \n",
      "Finished 41000 out of 45020 \n",
      "Finished 42000 out of 45020 \n",
      "Finished 43000 out of 45020 \n",
      "Finished 44000 out of 45020 \n",
      "Finished 45000 out of 45020 \n"
=======
      "Finished 0 out of 45020 \n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe6 in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-581cd9b9f67b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mtranslation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrench_sent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmax_ind\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mcurr_phrase_block\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menglish_sent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mprint\u001b[0m \u001b[1;34mu'{: <2} | {: <20} | {: <2} | {: <30} | {: <30} | {: <10} '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_phrase_block\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_start\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;34m' -> '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0mactionset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurr_phrase_block\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mtarget_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_ind\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_start\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Max to handle the case where a word in the source maps backwards in the target\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe6 in position 0: ordinal not in range(128)"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "#print '==============================================================================================='\n",
    "actions = []\n",
    "for ind, (alignment, english_sent, french_sent) in enumerate(zip(alignments, english_sents, french_sents)):\n",
    "    \n",
    "    if ind % 1000 == 0:\n",
    "        print 'Finished %d out of %d ' %(ind, len(english_sents))\n",
    "    indices = set()\n",
    "    backward_alignment, forward_alignment = parse_alignment(alignment)\n",
    "    not_in_target = get_not_in_target(alignment)\n",
    "    target_start = 0\n",
    "    source_start = 0\n",
    "    actionset = []\n",
    "    \n",
    "    for ind, word in enumerate(english_sent):\n",
    "        \n",
    "        # If word in source doesn't have an alignment, SHIFT\n",
    "        if ind not in forward_alignment:\n",
    "            #print u'{: <2} | {: <20} | {: <2} | {: <30} | {: <30} '.format(ind, word, 'NS', ' '.join(english_sent[source_start:ind+1]), 'NULL')\n",
    "            actionset.append([word, 'S', ' '.join(english_sent[source_start:ind+1]), ' '.join(english_sent[ind+1:]),  '$NONE$'])\n",
    "            continue\n",
    "        \n",
    "        # Add all the alignments for this word to indices\n",
    "        for item in forward_alignment[ind]:\n",
    "            indices.add(item)\n",
    "        action = 'T'\n",
    "        max_ind = max(indices)\n",
    "        \n",
    "        # Check if all target indices of the max spanning source block alignment are contained if not, SHIFT\n",
    "        for i in range(target_start, max_ind):\n",
    "            if i in not_in_target:\n",
    "                continue\n",
    "            if i not in indices:\n",
    "                action = 'S'\n",
    "                break\n",
    "        \n",
    "        # Write the SHIFT action to the actionset\n",
    "        if action == 'S':\n",
    "            #print u'{: <2} | {: <20} | {: <2} | {: <30} | {: <30} | {: <10}  '.format(ind, word, action, ' '.join(english_sent[source_start:ind+1]), 'NULL', str(target_start) + ', ' + str(max_ind) + ' -> ' + ' '.join([str(x) for x in indices]))\n",
    "            actionset.append([word, action, ' '.join(english_sent[source_start:ind+1]), ' '.join(english_sent[ind+1:]), '$NONE$'])\n",
    "        \n",
    "        # Write the TRANSLATE action to the actionset\n",
    "        elif action == 'T':\n",
    "            translation = french_sent[target_start:max_ind+1]\n",
    "            curr_phrase_block = english_sent[source_start:ind+1]\n",
<<<<<<< Updated upstream
    "            #print u'{: <2} | {: <20} | {: <2} | {: <30} | {: <30} | {: <10} '.format(ind, word, action, ' '.join(curr_phrase_block), ' '.join(translation), str(target_start)  + ' -> ' + str(max_ind))\n",
    "            actionset.append([word, action, ' '.join(curr_phrase_block), ' '.join(english_sent[ind+1:]), ' '.join(translation) if translation != [] else '$NONE$'])\n",
=======
    "            print u'{: <2} | {: <20} | {: <2} | {: <30} | {: <30} | {: <10} '.format(ind, word, action, ' '.join(curr_phrase_block), u' '.join(translation), str(target_start)  + ' -> ' + str(max_ind))\n",
    "            actionset.append([word, action, curr_phrase_block, translation])\n",
>>>>>>> Stashed changes
    "            target_start = max(max_ind + 1, target_start) # Max to handle the case where a word in the source maps backwards in the target\n",
    "            source_start = ind + 1\n",
    "            indices = set()\n",
    "    actionset.insert(0, ' '.join(french_sent))\n",
    "    actionset.insert(0, ' '.join(english_sent))\n",
    "    #print ' '.join(french_sent)\n",
    "    #print '==============================================================================================='\n",
    "    actions.append(actionset)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = codecs.open('oracle.en.zh.tsv', 'w', encoding='utf8')\n",
    "for actionset in actions:\n",
    "    f.write(actionset[0] + '\\n')\n",
    "    f.write(actionset[1] + '\\n')\n",
    "    for action in actionset[2:]:\n",
    "        f.write(' ||| '.join(action) + '\\n')\n",
    "    f.write('\\n')\n",
    "f.close()"
=======
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\xe6\\x9c\\x89']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
