{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "import codecs\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu2\")\n",
    "from collections import Counter\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('/usr0/home/glample/Research/perso/UltraDeep/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from network import LSTM\n",
    "from layer import HiddenLayer, EmbeddingLayer\n",
    "from learning_method import LearningMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_en = '/usr0/home/glample/Research/IncrementalMT/news-commentary-v8.fr-en.clean.en'\n",
    "path_to_fr = '/usr0/home/glample/Research/IncrementalMT/news-commentary-v8.fr-en.clean.fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_sentences = [line.strip().split() for line in codecs.open(path_to_en, 'r', encoding='utf-8')]\n",
    "french_sentences = [line.strip().split() for line in codecs.open(path_to_fr, 'r', encoding='utf-8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(english_sentences) == len(french_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences_eng = english_sentences[:int(0.95 * len(english_sentences))]\n",
    "dev_sentences_eng = english_sentences[int(0.95 * len(english_sentences)):int(0.97 * len(english_sentences))]\n",
    "test_sentences_en = english_sentences[int(0.97 * len(english_sentences)):]\n",
    "\n",
    "train_sentences_fr = french_sentences[:int(0.95 * len(french_sentences))]\n",
    "dev_sentences_fr = french_sentences[int(0.95 * len(french_sentences)):int(0.97 * len(french_sentences))]\n",
    "test_sentences_fr = french_sentences[int(0.97 * len(french_sentences)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_words = set()\n",
    "for sentence in english_sentences:\n",
    "    for word in sentence:\n",
    "        source_words.add(word)\n",
    "source_words.add('<s>')\n",
    "source_words.add('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_words = set()\n",
    "for sentence in french_sentences:\n",
    "    for word in sentence:\n",
    "        target_words.add(word)\n",
    "target_words.add('<s>')\n",
    "target_words.add('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_word2ind = {word:ind for ind, word in enumerate(source_words)}\n",
    "source_ind2word = {ind:word for ind, word in enumerate(source_words)}\n",
    "target_word2ind = {word:ind for ind, word in enumerate(target_words)}\n",
    "target_ind2word = {ind:word for ind, word in enumerate(target_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_inp = T.ivector()\n",
    "tgt_inp = T.ivector()\n",
    "tgt_op = T.ivector()\n",
    "index = T.scalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src_embedding_layer = EmbeddingLayer(input_dim=len(source_word2ind), output_dim=64)\n",
    "tgt_embedding_layer = EmbeddingLayer(input_dim=len(target_word2ind), output_dim=64)\n",
    "src_lstm_forward = LSTM(input_dim=src_embedding_layer.output_dim, hidden_dim=128, with_batch=False)\n",
    "src_lstm_backward = LSTM(input_dim=src_embedding_layer.output_dim, hidden_dim=128, with_batch=False)\n",
    "tgt_lstm = LSTM(input_dim=tgt_embedding_layer.output_dim, hidden_dim=2 * src_lstm_forward.hidden_dim, with_batch=False)\n",
    "tgt_projection_layer = HiddenLayer(input_dim=tgt_lstm.hidden_dim * 2, output_dim=len(target_word2ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_inp_t = np.random.rand(5,).astype(np.int32)\n",
    "tgt_inp_t = np.random.rand(5,).astype(np.int32)\n",
    "tgt_op_t = np.random.rand(5,).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Model\n",
    "#\n",
    "src_emb_dim      = 256  # source word embedding dimension\n",
    "tgt_emb_dim      = 256  # target word embedding dimension\n",
    "src_lstm_hid_dim = 512  # source LSTMs hidden dimension\n",
    "tgt_lstm_hid_dim = 2 * src_lstm_hid_dim  # target LSTM hidden dimension\n",
    "proj_dim         = 104  # size of the first projection layer\n",
    "dropout          = 0.5  # dropout rate\n",
    "\n",
    "n_src = len(source_word2ind)  # number of words in the source language\n",
    "n_tgt = len(target_word2ind)  # number of words in the target language\n",
    "\n",
    "# Parameters\n",
    "params = []\n",
    "\n",
    "# Source words + target words embeddings layer\n",
    "src_lookup = EmbeddingLayer(n_src, src_emb_dim, name='src_lookup') # lookup table for source words\n",
    "tgt_lookup = EmbeddingLayer(n_tgt, tgt_emb_dim, name='tgt_lookup') # lookup table for target words\n",
    "params += src_lookup.params + tgt_lookup.params\n",
    "\n",
    "# LSTMs\n",
    "src_lstm_for = LSTM(src_emb_dim, src_lstm_hid_dim, name='src_lstm_for', with_batch=False)\n",
    "src_lstm_rev = LSTM(src_emb_dim, src_lstm_hid_dim, name='src_lstm_rev', with_batch=False)\n",
    "tgt_lstm = LSTM(2 * tgt_emb_dim, tgt_lstm_hid_dim, name='tgt_lstm', with_batch=False)\n",
    "params += src_lstm_for.params + src_lstm_rev.params + tgt_lstm.params[:-1]\n",
    "\n",
    "# Projection layers\n",
    "proj_layer1 = HiddenLayer(tgt_lstm_hid_dim + 2 * src_lstm_hid_dim, n_tgt, name='proj_layer1', activation='softmax')\n",
    "proj_layer2 = HiddenLayer(2 * src_lstm_hid_dim, tgt_emb_dim, name='proj_layer2', activation='tanh')\n",
    "params += proj_layer1.params # + proj_layer2.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_train_t = 1\n",
    "\n",
    "src_sentence_t = [3, 4, 2]\n",
    "tgt_sentence_t = [1, 8, 0, 8, 2]\n",
    "tgt_gold_t = [1, 3, 2, 2, 1]\n",
    "beta = 500\n",
    "\n",
    "\n",
    "# Train status\n",
    "is_train = T.iscalar('is_train')\n",
    "# Input sentence\n",
    "src_sentence = T.ivector()\n",
    "# Current output translation\n",
    "tgt_sentence = T.ivector()\n",
    "# Gold translation\n",
    "tgt_gold = T.ivector()\n",
    "\n",
    "src_sentence_emb = src_lookup.link(src_sentence)\n",
    "tgt_sentence_emb = tgt_lookup.link(tgt_sentence)\n",
    "print 'src_sentence_emb', src_sentence_emb.eval({src_sentence: src_sentence_t}).shape\n",
    "print 'tgt_sentence_emb', tgt_sentence_emb.eval({tgt_sentence: tgt_sentence_t}).shape\n",
    "\n",
    "src_lstm_for.link(src_sentence_emb)\n",
    "src_lstm_rev.link(src_sentence_emb[::-1, :])\n",
    "\n",
    "print 'src_lstm_for.h', src_lstm_for.h.eval({src_sentence: src_sentence_t}).shape\n",
    "print 'src_lstm_rev.h', src_lstm_rev.h.eval({src_sentence: src_sentence_t}).shape\n",
    "\n",
    "src_context = T.concatenate([src_lstm_for.h, src_lstm_rev.h[::-1, :]], axis=1)\n",
    "print 'src_context', src_context.eval({src_sentence: src_sentence_t}).shape\n",
    "\n",
    "tgt_lstm.h_0 = src_context[-1]\n",
    "#repeated_src_context = T.repeat(src_context[-1].dimshuffle('x', 0), tgt_sentence_emb.shape[0], axis=0)\n",
    "#repeated_src_context = proj_layer2.link(repeated_src_context)\n",
    "#print 'repeated src_context', repeated_src_context.eval({src_sentence: src_sentence_t, tgt_sentence: tgt_sentence_t}).shape\n",
    "#tgt_sentence_emb = T.concatenate((tgt_sentence_emb, repeated_src_context), axis=1)\n",
    "print 'tgt sentence emb', tgt_sentence_emb.eval({src_sentence: src_sentence_t, tgt_sentence: tgt_sentence_t}).shape\n",
    "tgt_lstm.link(tgt_sentence_emb)\n",
    "print 'tgt_lstm.h', tgt_lstm.h.eval({src_sentence: src_sentence_t, tgt_sentence: tgt_sentence_t}).shape\n",
    "\n",
    "transition = tgt_lstm.h.dot(src_context.transpose())\n",
    "transition = transition.dot(src_context)\n",
    "print 'transition', transition.eval({src_sentence: src_sentence_t, tgt_sentence: tgt_sentence_t}).shape\n",
    "# print 'transition_matrix', transition_matrix.eval({src_sentence: src_sentence_t}).shape\n",
    "# print 'transition_matrix.dot(tgt_lstm.output)', src_context.transpose().dot(src_context.dot(tgt_lstm.output)).eval({src_sentence: src_sentence_t, tgt_sentence: tgt_sentence_t}).shape\n",
    "# print 'transition_matrix.dot(tgt_lstm.output)', tgt_lstm.h.dot(transition_matrix).eval({src_sentence: src_sentence_t, tgt_sentence: tgt_sentence_t}).shape\n",
    "\n",
    "transition_last = T.concatenate([transition, tgt_lstm.h], axis=1)\n",
    "print 'transition_last', transition_last.eval({src_sentence: src_sentence_t, tgt_sentence: tgt_sentence_t}).shape\n",
    "\n",
    "prediction = proj_layer1.link(transition_last)\n",
    "print 'prediction', prediction.eval({src_sentence: src_sentence_t, tgt_sentence: tgt_sentence_t}).shape\n",
    "\n",
    "cost = T.nnet.categorical_crossentropy(prediction, tgt_gold).mean()\n",
    "cost += beta * T.mean((tgt_lstm.h[:-1] ** 2 - tgt_lstm.h[1:] ** 2) ** 2) # Regularization of RNNs from http://arxiv.org/pdf/1511.08400v6.pdf\n",
    "\n",
    "print 'cost', cost.eval({src_sentence: src_sentence_t, tgt_sentence: tgt_sentence_t, tgt_gold: tgt_gold_t})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updates=LearningMethod(clip=5.0).get_updates('adam', cost, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_train = theano.function(\n",
    "    inputs=[src_sentence, tgt_sentence, tgt_gold],\n",
    "    outputs=cost,\n",
    "    updates=updates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_eval = theano.function(\n",
    "    inputs=[src_sentence, tgt_sentence],\n",
    "    outputs=prediction,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_validation_predictions():\n",
    "    validation_predictions = []    \n",
    "    for ind, sent in enumerate(dev_sentences_eng[:100]):\n",
    "        \n",
    "        if ind % 300 == 0:\n",
    "            print ind, len(dev_sentences_eng)\n",
    "        src_words = np.array([source_word2ind[x] for x in sent]).astype(np.int32)\n",
    "        current_outputs = [target_word2ind['<s>']]\n",
    "\n",
    "        while True:\n",
    "            next_word = f_eval(src_words, current_outputs).argmax(axis=1)[-1]\n",
    "            current_outputs.append(next_word)\n",
    "            #print [target_ind2word[x] for x in current_outputs]\n",
    "            if next_word == target_word2ind['</s>'] or len(current_outputs) >= 15:\n",
    "                validation_predictions.append([target_ind2word[x] for x in current_outputs])\n",
    "                break\n",
    "    return validation_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_predictions():\n",
    "    test_predictions = []    \n",
    "    for ind, sent in enumerate(test_sentences_eng):\n",
    "        \n",
    "        if ind % 300 == 0:\n",
    "            print ind, len(test_sentences_eng)\n",
    "        src_words = np.array([source_word2ind[x] for x in sent]).astype(np.int32)\n",
    "        current_outputs = [target_word2ind['<s>']]\n",
    "\n",
    "        while True:\n",
    "            next_word = f_eval(src_words, current_outputs).argmax(axis=1)[-1]\n",
    "            current_outputs.append(next_word)\n",
    "            #print [target_ind2word[x] for x in current_outputs]\n",
    "            if next_word == target_word2ind['</s>'] or len(current_outputs) >= 15:\n",
    "                test_predictions.append([target_ind2word[x] for x in current_outputs])\n",
    "                break\n",
    "    return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> , les politiques ne pas des des politiques pour des , peut des idéales\n"
     ]
    }
   ],
   "source": [
    "print ' '.join(valid_preds[900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'though',\n",
       " u'it',\n",
       " u'is',\n",
       " u'ultimately',\n",
       " u'the',\n",
       " u'Egyptian',\n",
       " u'people',\n",
       " u'who',\n",
       " u'will',\n",
       " u'decide',\n",
       " u'the',\n",
       " u'country',\n",
       " u'\\u2019',\n",
       " u's',\n",
       " u'fate',\n",
       " u',',\n",
       " u'and',\n",
       " u'whether',\n",
       " u'it',\n",
       " u'can',\n",
       " u'finally',\n",
       " u'take',\n",
       " u'decisive',\n",
       " u'steps',\n",
       " u'towards',\n",
       " u'more',\n",
       " u'inclusive',\n",
       " u'political',\n",
       " u'institutions',\n",
       " u',',\n",
       " u'this',\n",
       " u'does',\n",
       " u'not',\n",
       " u'mean',\n",
       " u'that',\n",
       " u'outsiders',\n",
       " u'can',\n",
       " u'do',\n",
       " u'nothing',\n",
       " u'.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_sentences_eng[900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_valid_preds = None\n",
    "best_valid_score = -sys.maxint\n",
    "best_test_preds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "0 3.18894\n",
      "300 3.31635\n",
      "600 3.31026\n",
      "900 3.24681\n",
      "1200 3.25304\n",
      "1500 3.31975\n",
      "1800 3.31634\n",
      "2100 3.26617\n",
      "2400 3.40801\n",
      "2700 3.32076\n",
      "3000 3.41637\n",
      "3300 3.20238\n",
      "3600 3.45898\n",
      "3900 3.29132\n",
      "4200 3.35515\n",
      "4500 3.44128\n",
      "4800 3.29924\n",
      "5100 3.34561\n",
      "5400 3.3237\n",
      "5700 3.33885\n",
      "6000 3.34944\n",
      "6300 3.25173\n",
      "6600 3.35672\n",
      "6900 3.20916\n",
      "7200 3.39585\n",
      "7500 3.41353\n",
      "7800 3.4373\n",
      "8100 3.39742\n",
      "8400 3.35773\n",
      "8700 3.44127\n",
      "9000 3.40045\n",
      "9300 3.29823\n",
      "9600 3.42785\n",
      "9900 3.38059\n",
      "0 3108\n",
      "300 3108\n",
      "600 3108\n",
      "900 3108\n",
      "1200 3108\n",
      "1500 3108\n",
      "1800 3108\n",
      "2100 3108\n",
      "2400 3108\n",
      "2700 3108\n",
      "3000 3108\n",
      "===================================================================\n",
      "Epoch 0 BLEU on Validation : 0.00 \n",
      "===================================================================\n",
      "Found new best validation score 0.000000 \n",
      "10200 3.36053\n",
      "10500 3.40325\n",
      "10800 3.39586\n",
      "11100 3.30332\n",
      "11400 3.33042\n",
      "11700 3.29486\n",
      "12000 3.39685\n",
      "12300 3.44464\n",
      "12600 3.42495\n",
      "12900 3.36286\n",
      "13200 3.34129\n",
      "13500 3.51194\n",
      "13800 3.41034\n",
      "14100 3.32053\n",
      "14400 3.40615\n",
      "14700 3.41174\n",
      "15000 3.38293\n",
      "15300 3.54414\n",
      "15600 3.47826\n",
      "15900 3.48069\n",
      "16200 3.42324\n",
      "16500 3.33668\n",
      "16800 3.40387\n",
      "17100 3.41698\n",
      "17400 3.53604\n",
      "17700 3.50198\n",
      "18000 3.3582\n",
      "18300 3.45172\n",
      "18600 3.4034\n",
      "18900 3.31357\n",
      "19200 3.52362\n",
      "19500 3.50325\n",
      "19800 3.48596\n",
      "0 3108\n",
      "300 3108\n",
      "600 3108\n",
      "900 3108\n",
      "1200 3108\n",
      "1500 3108\n",
      "1800 3108\n",
      "2100 3108\n",
      "2400 3108\n",
      "2700 3108\n",
      "3000 3108\n",
      "===================================================================\n",
      "Epoch 0 BLEU on Validation : 0.00 \n",
      "===================================================================\n",
      "Found new best validation score 0.000000 \n",
      "20100 3.42402\n",
      "20400 3.44799\n",
      "20700 3.47828\n",
      "21000 3.33306\n",
      "21300 3.50301\n",
      "21600 3.41591\n",
      "21900 3.48399\n",
      "22200 3.42687\n",
      "22500 3.44165\n",
      "22800 3.44356\n",
      "23100 3.47262\n",
      "23400 3.4737\n",
      "23700 3.63361\n",
      "24000 3.3947\n",
      "24300 3.44944\n",
      "24600 3.47343\n",
      "24900 3.55283\n",
      "25200 3.46853\n",
      "25500 3.41004\n",
      "25800 3.48896\n",
      "26100 3.5767\n",
      "26400 3.46066\n",
      "26700 3.53494\n",
      "27000 3.4831\n",
      "27300 3.44515\n",
      "27600 3.46375\n",
      "27900 3.53379\n",
      "28200 3.43221\n",
      "28500 3.44676\n",
      "28800 3.55863\n",
      "29100 3.45015\n",
      "29400 3.42662\n",
      "29700 3.58612\n",
      "30000 3.52773\n",
      "0 3108\n",
      "300 3108\n",
      "600 3108\n",
      "900 3108\n",
      "1200 3108\n",
      "1500 3108\n",
      "1800 3108\n",
      "2100 3108\n",
      "2400 3108\n",
      "2700 3108\n",
      "3000 3108\n",
      "===================================================================\n",
      "Epoch 0 BLEU on Validation : 0.00 \n",
      "===================================================================\n",
      "Found new best validation score 0.000000 \n",
      "30300 3.44598\n",
      "30600 3.4493\n",
      "30900 3.45533\n",
      "31200 3.62673\n",
      "31500 3.53065\n",
      "31800 3.49246\n",
      "32100 3.41599\n",
      "32400 3.43766\n",
      "32700 3.42059\n",
      "33000 3.51164\n",
      "33300 3.49086\n",
      "33600 3.42199\n",
      "33900 3.63342\n",
      "34200 3.54989\n",
      "34500 3.41141\n",
      "34800 3.41699\n",
      "35100 3.3934\n",
      "35400 3.4433\n",
      "35700 3.44608\n",
      "36000 3.62078\n",
      "36300 3.46459\n",
      "36600 3.66802\n",
      "36900 3.42763\n",
      "37200 3.45224\n",
      "37500 3.63033\n",
      "37800 3.54799\n",
      "38100 3.51261\n",
      "38400 3.46308\n",
      "38700 3.62182\n",
      "39000 3.51879\n",
      "39300 3.43839\n",
      "39600 3.58536\n",
      "39900 3.56468\n",
      "0 3108\n",
      "300 3108\n",
      "600 3108\n",
      "900 3108\n",
      "1200 3108\n",
      "1500 3108\n",
      "1800 3108\n",
      "2100 3108\n",
      "2400 3108\n",
      "2700 3108\n",
      "3000 3108\n",
      "===================================================================\n",
      "Epoch 0 BLEU on Validation : 0.00 \n",
      "===================================================================\n",
      "Found new best validation score 0.000000 \n",
      "40200 3.56108\n",
      "40500 3.62053\n",
      "40800 3.52294\n",
      "41100 3.41317\n",
      "41400 3.55953\n",
      "41700 3.48007\n",
      "42600 3.62303\n",
      "42900 3.48936\n",
      "43200 3.67539\n",
      "43500 3.60791\n",
      "43800 3.56681\n",
      "44100 3.5764\n",
      "44400 3.50321\n",
      "44700 3.53479\n",
      "45000 3.57281\n",
      "45300 3.55114\n",
      "45600 3.60012\n",
      "45900 3.58092\n",
      "46200 3.61832\n",
      "46500 3.61396\n",
      "46800 3.57397\n",
      "47100 3.55729\n",
      "47400 3.57485\n",
      "47700 3.54111\n",
      "48000 3.43054\n",
      "48300 3.62663\n",
      "48600 3.56007\n",
      "48900 3.56158\n",
      "49200 3.58932\n",
      "49500 3.6794\n",
      "49800 3.52738\n",
      "0 3108\n",
      "300 3108\n",
      "600 3108\n",
      "900 3108\n",
      "1200 3108\n",
      "1500 3108\n",
      "1800 3108\n",
      "2100 3108\n",
      "2400 3108\n",
      "2700 3108\n",
      "3000 3108\n",
      "===================================================================\n",
      "Epoch 0 BLEU on Validation : 0.00 \n",
      "===================================================================\n",
      "Found new best validation score 0.000000 \n",
      "50100 3.54017\n",
      "50400 3.73758\n",
      "50700 3.63766\n",
      "51000 3.53261\n",
      "51300 3.54266\n",
      "51600 3.36723\n",
      "51900 3.69979\n",
      "66600 3.61883\n",
      "66900 3.61837\n",
      "67200 3.58846\n",
      "67500 3.72099\n",
      "67800 3.63869\n",
      "68100 3.55379\n",
      "68400 3.69275\n",
      "68700 3.68315\n",
      "69000 3.65646\n",
      "69300 3.50543\n",
      "69600 3.60517\n",
      "69900 3.64109\n",
      "0 3108\n",
      "300 3108\n",
      "600 3108\n",
      "900 3108\n",
      "1200 3108\n",
      "1500 3108\n",
      "1800 3108\n",
      "2100 3108\n",
      "2400 3108\n",
      "2700 3108\n",
      "3000 3108\n",
      "===================================================================\n",
      "Epoch 0 BLEU on Validation : 0.00 \n",
      "===================================================================\n",
      "Found new best validation score 0.000000 \n",
      "70200 3.54777\n",
      "70500 3.58868\n",
      "70800 3.56297\n",
      "71100 3.78944\n",
      "71400 3.62823\n",
      "71700 3.68555\n",
      "72000 3.67639\n",
      "72300 3.68897\n",
      "72600 3.64219\n",
      "72900 3.65203\n",
      "73200 3.61897\n",
      "73500 3.72762\n",
      "73800 3.57242\n",
      "74100 3.62492\n",
      "74400 3.67181\n",
      "74700 3.75805\n",
      "75000 3.50054\n",
      "75300 3.54444\n",
      "75600 3.62563\n",
      "75900 3.73581\n",
      "76200 3.55262\n",
      "76500 3.66695\n",
      "76800 3.52978\n",
      "77100 3.66945\n",
      "77400 3.51066\n",
      "77700 3.7154\n",
      "78000 3.51868\n",
      "78300 3.81246\n",
      "78600 3.70858\n",
      "78900 3.64022\n",
      "79200 3.58928\n",
      "79500 3.74528\n",
      "79800 3.64957\n",
      "0 3108\n",
      "300 3108\n",
      "600 3108\n",
      "900 3108\n",
      "1200 3108\n",
      "1500 3108\n",
      "1800 3108\n",
      "2100 3108\n",
      "2400 3108\n",
      "2700 3108\n",
      "3000 3108\n",
      "===================================================================\n",
      "Epoch 0 BLEU on Validation : 0.00 \n",
      "===================================================================\n",
      "Found new best validation score 0.000000 \n",
      "80100 3.59861\n",
      "80400 3.69511\n",
      "80700 3.65631\n",
      "81000 3.82279\n",
      "81300 3.52908\n",
      "81600 3.6377\n",
      "81900 3.57587\n",
      "82200 3.68247\n",
      "82500 3.62407\n",
      "82800 3.64476\n",
      "83100 3.70275\n",
      "83400 3.65325\n",
      "83700 3.68104\n",
      "84000 3.71509\n",
      "84300 3.69895\n",
      "84600 3.67358\n",
      "84900 3.56021\n",
      "85200 3.70526\n",
      "85500 3.76961\n",
      "85800 3.62182\n",
      "86100 3.63962\n",
      "86400 3.68027\n",
      "86700 3.58612\n",
      "87000 3.68914\n",
      "87300 3.64263\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-d50ad6b4dc99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource_word2ind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'<s>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msource_word2ind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_src_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msource_word2ind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'</s>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_word2ind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'<s>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtarget_word2ind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_tgt_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_word2ind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_tgt_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtarget_word2ind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'</s>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         )\n\u001b[0;32m     20\u001b[0m         \u001b[0mall_costs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_cost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr0/home/glample/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr0/home/glample/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    949\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 951\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr0/home/glample/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    938\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                         self, node)\n\u001b[0m\u001b[0;32m    941\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f = open('blue_valid_log.txt', 'w')\n",
    "all_costs = []\n",
    "batch_size = 50\n",
    "n_epochs = 100\n",
    "for i in xrange(n_epochs):\n",
    "    print 'Starting epoch %i' % i\n",
    "    indices = range(len(train_sentences_eng))\n",
    "    np.random.shuffle(indices)\n",
    "    train_src_batch = [train_sentences_eng[ind] for ind in indices]\n",
    "    train_tgt_batch = [train_sentences_fr[ind] for ind in indices]\n",
    "    assert len(train_src_batch) == len(train_tgt_batch)\n",
    "    costs = []\n",
    "    for j in xrange(len(train_src_batch)):\n",
    "        #s_sent, s_length, t_inp, t_op, mask = get_batch(train_src_batch[j:j + batch_size], train_tgt_batch[j:j+batch_size])\n",
    "        new_cost = f_train(\n",
    "            np.array([source_word2ind['<s>']] + [source_word2ind[x] for x in train_src_batch[j]] + [source_word2ind['</s>']]).astype(np.int32),\n",
    "            np.array([target_word2ind['<s>']] + [target_word2ind[x] for x in train_tgt_batch[j]][:-1]).astype(np.int32),\n",
    "            np.array([target_word2ind[x] for x in train_tgt_batch[j]][1:] + [target_word2ind['</s>']]).astype(np.int32),\n",
    "        )\n",
    "        all_costs.append((j, new_cost))\n",
    "        costs.append(new_cost)\n",
    "        if j % 300 == 0:\n",
    "            print j, np.mean(costs)\n",
    "            costs = []\n",
    "        if np.isnan(new_cost):\n",
    "            print 'NaN detected.'\n",
    "            break\n",
    "        if j % 10000 == 0 and j != 0:\n",
    "            valid_preds = get_validation_predictions()\n",
    "            print '==================================================================='\n",
    "            print 'Epoch %i BLEU on Validation : %s ' % (i, get_validation_bleu(valid_preds))\n",
    "            print '==================================================================='\n",
    "            if float(get_validation_bleu(valid_preds)) >= best_valid_score:\n",
    "                best_valid_score = float(get_validation_bleu(valid_preds))\n",
    "                best_valid_preds = copy.deepcopy(valid_preds)\n",
    "                #best_test_preds = get_test_predictions()\n",
    "                print 'Found new best validation score %f ' % (best_valid_score)\n",
    "            f.write('Epoch %d Minibatch %d BLEU on Validation : %s \\n' % (i, j, get_validation_bleu(valid_preds)))\n",
    "\n",
    "    if np.isnan(new_cost):\n",
    "        print 'NaN detected.'\n",
    "        break\n",
    "    valid_preds = get_validation_predictions()\n",
    "    print '==================================================================='\n",
    "    print 'Epoch %i BLEU on Validation : %s ' % (i, get_validation_bleu(valid_preds))\n",
    "    print '==================================================================='\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = f_eval(\n",
    "    np.array([source_word2ind['<s>']] + [source_word2ind[x] for x in train_src_batch[j]] + [source_word2ind['</s>']]).astype(np.int32), \n",
    "    np.array([target_word2ind['<s>']] + [target_word2ind[x] for x in train_tgt_batch[j]][:-1]).astype(np.int32),\n",
    ").argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’ l&apos; ’ alternative n ’ est pas sûr . . </s>\n"
     ]
    }
   ],
   "source": [
    "print ' '.join([target_ind2word[x] for x in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> naturellement , l ’ alternative n ’ est pas plus sûre\n"
     ]
    }
   ],
   "source": [
    "yy = np.array([target_word2ind['<s>']] + [target_word2ind[x] for x in train_tgt_batch[j]][:-1]).astype(np.int32)\n",
    "print ' '.join([target_ind2word[x] for x in yy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bleu_stats(hypothesis, reference):\n",
    "    stats = []\n",
    "    stats.append(len(hypothesis))\n",
    "    stats.append(len(reference))\n",
    "    for n in xrange(1,5):\n",
    "        s_ngrams = Counter([tuple(hypothesis[i:i+n]) for i in xrange(len(hypothesis)+1-n)])\n",
    "        r_ngrams = Counter([tuple(reference[i:i+n]) for i in xrange(len(reference)+1-n)])\n",
    "        stats.append(max([sum((s_ngrams & r_ngrams).values()), 0]))\n",
    "        stats.append(max([len(hypothesis)+1-n, 0]))\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bleu(stats):\n",
    "    if len(filter(lambda x: x==0, stats)) > 0:\n",
    "        return 0\n",
    "    (c, r) = stats[:2]\n",
    "    log_bleu_prec = sum([math.log(float(x)/y) for x,y in zip(stats[2::2],stats[3::2])]) / 4.\n",
    "    return math.exp(min([0, 1-float(r)/c]) + log_bleu_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_validation_bleu(hypotheses):\n",
    "    stats = np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "    for hyp, ref in zip(hypotheses, dev_sentences_fr):\n",
    "        stats += np.array(bleu_stats(hyp, ref))\n",
    "    return \"%.2f\" % (100*bleu(stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
