{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append('SanDeepLearn/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'recurrent' from 'SanDeepLearn/recurrent.pyc'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import recurrent\n",
    "from layer import EmbeddingLayer\n",
    "from recurrent import RNN, LSTM\n",
    "from utils import get_weights, get_bias\n",
    "from optimizers import Optimizer\n",
    "reload(recurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data = 'Data/dev-test-train.de-en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = [line.strip().split('|||') for line in open(path_to_data, 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "german_lines, english_lines = [x[0].strip() for x in lines], [x[1].strip() for x in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "german_vocab = {}\n",
    "inv_german_vocab = {}\n",
    "vocab_ind = 0\n",
    "for line in german_lines:\n",
    "    line = line.split()\n",
    "    for word in line:\n",
    "        if word not in german_vocab:\n",
    "            german_vocab[word] = vocab_ind\n",
    "            inv_german_vocab[vocab_ind] = word\n",
    "            vocab_ind += 1\n",
    "german_vocab['<UNK>'] = vocab_ind\n",
    "inv_german_vocab[vocab_ind] = '<UNK>'\n",
    "german_vocab['<STOP>'] = vocab_ind + 1\n",
    "inv_german_vocab[vocab_ind + 1] = '<STOP>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "english_vocab = {}\n",
    "inv_english_vocab = {}\n",
    "vocab_ind = 0\n",
    "for line in english_lines:\n",
    "    line = line.split()\n",
    "    for word in line:\n",
    "        if word not in english_vocab:\n",
    "            english_vocab[word] = vocab_ind\n",
    "            inv_english_vocab[vocab_ind] = word\n",
    "            vocab_ind += 1\n",
    "english_vocab['<UNK>'] = vocab_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_inp = T.ivector()\n",
    "dec_inp = T.ivector()\n",
    "expected_output = T.imatrix()\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "english_embedding = EmbeddingLayer(len(english_vocab), 100) # Randomly initialized word embeddings for english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "german_embedding = EmbeddingLayer(len(german_vocab), 100) # Randomly initialized word embeddings for german"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_rnn = LSTM(100, 100, return_type='last') # Encoder RNN that returns the final activation for a sequence of english words (no start or stop)\n",
    "decoder_rnn = LSTM(100, 100, return_type='all') # Decoder RNN that returns the activation at each step while decoding (includes a <STOP>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Initializes the weights that are needed to project the decoder activation at each step onto the vocabulary size\n",
    "'''\n",
    "input_dim = decoder_rnn.output_dim \n",
    "output_dim = len(german_vocab)\n",
    "low = -4 * np.sqrt(6. / (input_dim + output_dim))\n",
    "high = 4 * np.sqrt(6. / (input_dim + output_dim))\n",
    "softmax_project_weights = get_weights(low=low, high=high, shape=(input_dim, output_dim), name='decoder_softmax_projection_weights')\n",
    "softmax_project_bias = get_bias(output_dim, name='decoder_softmax_projection_bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_embeddings = english_embedding.fprop(enc_inp[::-1]) # Transform sequence of indices into a matrix for the source sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_rnn_output = encoder_rnn.fprop(source_embeddings) # Propogate the embedding matrix through the encoder RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_embeddings = T.vertical_stack((encoder_rnn_output.reshape((1, -1))), german_embedding.fprop(dec_inp[:-1])) # Creates the embedding matrix to propogate through the decoder RNN need to reshape the encoder RNN activation into a matrix for Theano vertical stack :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_outputs = decoder_rnn.fprop(target_embeddings) # Propogate the target embedding matrix through the decoder RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_predictions = T.nnet.softmax(T.dot(decoder_outputs, softmax_project_weights) + softmax_project_bias) # Project activations onto the target vocabury space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_sentence = T.argmax(decoder_predictions, axis=1) # Get the sentence that corresponds to this projection by greedily picking max at each decoding step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = T.nnet.categorical_crossentropy(decoder_predictions, expected_output).mean() # Set the loss function to be the cross entropy between softmax output and expected output (expected output is one step ahead of the decoding at every step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = [softmax_project_weights, softmax_project_bias] + encoder_rnn.params + decoder_rnn.params + english_embedding.params + german_embedding.params # Set the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Update parameters using SGD\n",
    "'''\n",
    "updates = Optimizer().sgd(\n",
    "                loss,\n",
    "                params,\n",
    "                lr=lr\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef lm_helper(decoder_input):\\n    decoder_rnn_embedding = decoder_rnn.fprop(decoder_input)\\n    decoder_rnn_prediction = T.argmax(T.nnet.softmax(T.dot(decoder_rnn_embedding, softmax_project_weights))).flatten()\\n    return T.concatenate((decoder_input, german_embedding.fprop(decoder_rnn_prediction)), axis=0), theano.scan_module.until(T.eq(decoder_rnn_prediction[0], german_vocab['<STOP>']))\\n\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def lm_helper(decoder_input):\n",
    "    decoder_rnn_embedding = decoder_rnn.fprop(decoder_input)\n",
    "    decoder_rnn_prediction = T.argmax(T.nnet.softmax(T.dot(decoder_rnn_embedding, softmax_project_weights))).flatten()\n",
    "    return T.concatenate((decoder_input, german_embedding.fprop(decoder_rnn_prediction)), axis=0), theano.scan_module.until(T.eq(decoder_rnn_prediction[0], german_vocab['<STOP>']))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresults, _ = theano.scan(\\n    fn=lm_helper,\\n    outputs_info=[decoder_input], \\n    n_steps=100\\n)\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "results, _ = theano.scan(\n",
    "    fn=lm_helper,\n",
    "    outputs_info=[decoder_input], \n",
    "    n_steps=100\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#results_2, _ = theano.scan(\n",
    "#    fn=lambda x: (x ** 2, theano.scan_module.until(T.eq(x, 10))),\n",
    "#    outputs_info=[2],\n",
    "#    n_steps=100\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#f_temp = theano.function(\n",
    "#    inputs=[],\n",
    "#    outputs=results_2\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gets the encoder representation of the sentence from the computational graph\n",
    "f_encoder = theano.function(\n",
    "    inputs=[enc_inp],\n",
    "    outputs=encoder_rnn_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gets the decoder softmax output \n",
    "f_decoder = theano.function(\n",
    "    inputs=[enc_inp, dec_inp],\n",
    "    outputs=decoder_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trains the sequence-sequence model\n",
    "f_train = theano.function(\n",
    "    inputs=[enc_inp, dec_inp, expected_output],\n",
    "    outputs=loss,\n",
    "    updates=updates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gets the indices of the words in the decoded sentence\n",
    "f_decoded_sentence = theano.function(\n",
    "    inputs=[enc_inp, dec_inp],\n",
    "    outputs = decoder_sentence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#english_sentence = english_lines[0].split()\n",
    "#test_english_sentence = [english_vocab[word] for word in english_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#german_sentence = german_lines[0].split()\n",
    "#german_sentence.append('<STOP>')\n",
    "#test_german_sentence = [german_vocab[word] for word in german_sentence]\n",
    "#true_german_sentence = np.vstack([np.zeros(len(german_vocab)) for word in german_sentence]).astype(np.int32)\n",
    "#for ind, word in enumerate(german_sentence):\n",
    "#    true_german_sentence[ind][german_vocab[word]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#f_decoder(test_english_sentence, test_german_sentence).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print ' '.join([inv_german_vocab[word] for word in f_decoded_sentence(test_english_sentence, test_german_sentence)])\n",
    "#f_train(test_english_sentence, test_german_sentence, true_german_sentence)\n",
    "#print ' '.join([inv_german_vocab[word] for word in f_decoded_sentence(test_english_sentence, test_german_sentence)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "Decoded sentence : Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme \n",
      "Actual sentence : ( Das Parlament erhebt sich zu einer Schweigeminute . ) <STOP> \n",
      "Epoch : 0 loss : nan\n",
      "=========================================================================================\n",
      "=========================================================================================\n",
      "Decoded sentence : Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme \n",
      "Actual sentence : Wäre es angemessen , wenn Sie , Frau Präsidentin , der Präsidentin von Sri Lanka in einem Schreiben das Bedauern des Parlaments zum gewaltsamen Tod von Herrn Ponnambalam und anderen Bürgern von Sri Lanka übermitteln und sie auffordern würden , alles in ihrem Kräften stehende zu tun , um nach einer friedlichen Lösung dieser sehr schwierigen Situation zu suchen ? <STOP> \n",
      "Epoch : 0 loss : nan\n",
      "=========================================================================================\n",
      "=========================================================================================\n",
      "Decoded sentence : Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme \n",
      "Actual sentence : Das Parlament wird sich am Donnerstag mit dem Cunha-Bericht über mehrjährige Ausrichtungsprogramme befassen , der in Absatz 6 vorschlägt , daß Länder , die ihr Soll zur Flottenverkleinerung nicht erfüllen , jährlich mit einer Art Quotenstrafe belegt werden sollen . <STOP> \n",
      "Epoch : 0 loss : nan\n",
      "=========================================================================================\n",
      "=========================================================================================\n",
      "Decoded sentence : Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme \n",
      "Actual sentence : Die erste diesjährige Tagung des Europäischen Parlaments fällt leider damit zusammen , daß in den Vereinigten Staaten , in Texas , für Donnerstag dieser Woche die Hinrichtung eines zum Tode verurteilten 34jährigen jungen Mannes namens Hicks festgelegt worden ist . <STOP> \n",
      "Epoch : 0 loss : nan\n",
      "=========================================================================================\n",
      "=========================================================================================\n",
      "Decoded sentence : Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme \n",
      "Actual sentence : Nun ist es aber so , daß er wieder angeklagt werden soll , weil der Staatsanwalt in Berufung geht . <STOP> \n",
      "Epoch : 0 loss : nan\n",
      "=========================================================================================\n",
      "=========================================================================================\n",
      "Decoded sentence : Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme \n",
      "Actual sentence : Deshalb möchte ich Sie nochmals ersuchen , dafür Sorge zu tragen , daß auch ein niederländischer Sender eingespeist wird . <STOP> \n",
      "Epoch : 0 loss : nan\n",
      "=========================================================================================\n",
      "=========================================================================================\n",
      "Decoded sentence : Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme \n",
      "Actual sentence : Warum wird in den Nichtraucherzonen das Rauchverbot nicht durchgesetzt ? <STOP> \n",
      "Epoch : 0 loss : nan\n",
      "=========================================================================================\n",
      "=========================================================================================\n",
      "Decoded sentence : Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme \n",
      "Actual sentence : Frau Lynne , Sie haben völlig recht , und ich werde prüfen , ob all dies wirklich so ist . <STOP> \n",
      "Epoch : 0 loss : nan\n",
      "=========================================================================================\n",
      "=========================================================================================\n",
      "Decoded sentence : Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme \n",
      "Actual sentence : Das heißt , alle Fraktionen , mit Ausnahme der Fraktionslosen - aber die sind ja keine Fraktion - waren sich einig , nur Ihre Fraktion war der Meinung , so zu verfahren , wie Sie es hier vorgeschlagen haben . <STOP> \n",
      "Epoch : 0 loss : nan\n",
      "=========================================================================================\n",
      "=========================================================================================\n",
      "Decoded sentence : Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme \n",
      "Actual sentence : Ich schlage vor , daß wir über den Antrag der Sozialdemokratischen Fraktion , die Erklärung der Kommission über ihre strategischen Ziele wieder auf die Tagesordnung zu setzen , abstimmen . <STOP> \n",
      "Epoch : 0 loss : nan\n",
      "=========================================================================================\n",
      "=========================================================================================\n",
      "Decoded sentence : Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme \n",
      "Actual sentence : Möchte jemand den Antrag im Namen der Fraktion begründen ? <STOP> \n",
      "Epoch : 0 loss : nan\n",
      "=========================================================================================\n",
      "=========================================================================================\n",
      "Decoded sentence : Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme \n",
      "Actual sentence : Frau Präsidentin ! Ich will die Debatte nicht wieder aufnehmen , aber ich hatte mich auch gemeldet , um zu dem Antrag von Herrn Barón Crespo Stellung zu nehmen . <STOP> \n",
      "Epoch : 0 loss : nan\n",
      "=========================================================================================\n",
      "=========================================================================================\n",
      "Decoded sentence : Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme Wiederaufnahme \n",
      "Actual sentence : Ich denke , wir sollten hier im Rahmen der europäischen Landwirtschaftspolitik auch dafür sorgen , daß weiterhin diese Tomaten in diesen Regionen angebaut , geerntet und verarbeitet werden können . <STOP> \n",
      "Epoch : 0 loss : nan\n",
      "=========================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-f581a8ee8cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgerman_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mtrue_german_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgerman_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_german_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minv_german_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf_decoded_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgerman_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sandeepsubramanian/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sandeepsubramanian/anaconda/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mallow_gc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_gc\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_gc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0m\u001b[1;32m    671\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m    672\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for ind, (english_sentence, german_sentence) in enumerate(zip(english_lines, german_lines)):\n",
    "        english_sentence = [english_vocab[word] for word in english_sentence.split()]\n",
    "        german_sentence = [german_vocab[word] for word in german_sentence.split()]\n",
    "        german_sentence.append(german_vocab['<STOP>'])\n",
    "        true_german_sentence = np.vstack([np.zeros(len(german_vocab)) for word in german_sentence]).astype(np.int32)\n",
    "        for ind, word in enumerate(german_sentence):\n",
    "            true_german_sentence[ind][word] = 1\n",
    "        loss = f_train(english_sentence, german_sentence, true_german_sentence)\n",
    "        if ind % 10 == 0:\n",
    "            decoded_sentence = [inv_german_vocab[word] for word in f_decoded_sentence(english_sentence, german_sentence)]\n",
    "            print '========================================================================================='\n",
    "            print 'Decoded sentence : %s ' % (' '.join(decoded_sentence))\n",
    "            print 'Actual sentence : %s ' % (' '.join([inv_german_vocab[word] for word in german_sentence]))\n",
    "            print 'Epoch : %d loss : %f' % (i, loss)\n",
    "            print '========================================================================================='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "84952",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-29ea6df0d56e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minv_german_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m84952\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 84952"
     ]
    }
   ],
   "source": [
    "inv_german_vocab[84952]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_representation = f_encoder(test_english_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_prediciton = f_decoder(test_english_sentence, test_german_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 84953)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_prediciton.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-konsum', 'Migrantenfamilien', 'Darbietungen', 'Sch\\xc3\\xa4rfung'] ['Wiederaufnahme', 'der', 'Sitzungsperiode']\n"
     ]
    }
   ],
   "source": [
    "print [inv_german_vocab[x] for x in decoder_prediciton], german_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "104734",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c15cdc854de9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minv_german_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m104734\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 104734"
     ]
    }
   ],
   "source": [
    "inv_german_vocab[104734]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aktionspl\\xc3\\xa4ne'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_german_vocab[decoder_prediciton_2[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OCP-LP'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_german_vocab[decoder_prediciton[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flatten{1}.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_rnn_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = np.ones((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.repeat(T.vector(), 2).ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat([1,2], 2, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile([1,2], (2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(a, (1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
